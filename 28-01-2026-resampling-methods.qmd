---
title: "Resampling Methods"
author: "Ayush Patel"
subtitle: "DDD: Elements of Statistical Machine Learning & Politics of Data"
institute: "At Azim Premji University, Bhopal"
date: today
date-format: "DD MMM, YYYY"
format: 
  revealjs:
    fig-height: 6
    fig-width: 14
    embed-resources: true
    margin-left: 50px
    margin-right: 50px
    slide-number: c/t
    width: 1400
    height: 850
    theme: [default, theme.scss]
    footer: "Email: ayush.ap58@gmail.com"
---

```{r}
#| include: false
#| warning: false

library(tidyverse)
library(openintro)
library(ISLR2)
```

# Hello

::::{.columns}

:::{.column}

[I am Ayush.]{.fragment fragment-index="1" style="font-size:45px"}

[I am a researcher working at the intersection of data, development and economics.]{.fragment fragment-index="2" style="font-size:25px"}

[I am a [RStudio (Posit) certified tidyverse Instructor.](https://education.rstudio.com/trainers/people/patel+ayush/)]{.fragment fragment-index="3" style="font-size:25px"}

[I am a Researcher at [Oxford Poverty and Human development Initiative (OPHI)](https://ophi.org.uk/), at the University of Oxford.]{.fragment fragment-index="4" style="font-size:25px"}

:::

:::{.column}

![[Hello (Eh bonjour– donc–.) by Charles Motte](https://www.metmuseum.org/art/collection/search/392118"Well)](https://images.metmuseum.org/CRDImages/dp/original/DP808141.jpg){fig-align="center" height=400 .lightbox}
 

:::

::::

# Did you come prepared?

::::{.columns}

:::{.column}
- You have installed R. If not see [this link]().

- You have installed RStudio/Positron/VScode or any other IDE. It is recommended that you work through an IDE

- You have the libraries `{tidyverse}  {caret} {ISLR} {ISLR2} {openintro} {broom} {MASS} {nnet} {e1071} {tidymodels}` installed

:::

:::{.column}

![[Armor (Gusoku) Helmet signed by Bamen Tomotsugu](https://www.metmuseum.org/art/collection/search/24975)](https://images.metmuseum.org/CRDImages/aa/original/DT5333.jpg){fig-align="center" height=400 .lightbox}


:::

::::


# Learning Goals

1. Apply resampling methods for *Model Assessment* (performance)
2. Apply resampling methods for *Model Selection* (flexiblity)

# Resampling Methods

>The process involves taking several samples from the training data and fitting the model of interest to learn more about the model.

# Motivation

[Training error rates are not the best to gauge the model's performance]{.fragment fragment-index='1'}
<br><br>
[Test data is not usually available]{.fragment fragment-index='2'}
<br><br>
[But test error rate are better to assess a model's performance]{.fragment fragment-index='3'}
<br><br>
[One of the ways to handle this is by using resampling methods to estimate tert error rates]{.fragment fragment-index='4'}

# Validation Set Approach

[Split the observation randomly into *training* and *Validation* set.]{.fragment fragment-index='1'}
<br><br>
[Use the *training set* to build/train the model.]{.fragment fragment-index='2'}
<br><br>
[Use the model to predict the responses of the *validation set*.]{.fragment fragment-index='3'}
<br><br>
[Compare various quality of fit and performance stats using *validation set*]{.fragment fragment-index='4'}

# Data

`Auto` as an example to learn Cross Validation

```{r}
#| echo: false
#| warning: false

Auto |>
    ggplot(aes(horsepower, mpg)) +
    geom_point(colour = "steelblue") +
    labs(
        x = "Horsepower",
        y = "Miles per gallon"
    ) +
        theme_minimal()

```

# Model in question

::::{.columns}

:::{.column}
```{r}
#| echo: true
#| eval: false

lm(mpg ~ horsepower, Auto) |>
    broom::glance()
```

```{r}
#| echo: false

lm(mpg ~ horsepower, Auto) |>
    broom::glance() |>
    kableExtra::kable() |>
    kableExtra::kable_styling() |>
    kableExtra::scroll_box(width = '100%', height = '250px')
```

:::

:::{.column}

```{r}
#| echo: true
#| eval: false
lm(mpg ~ poly(horsepower,2), Auto) |>
    broom::glance()
```

```{r}
#| echo: false

lm(mpg ~ poly(horsepower,2), Auto) |>
    broom::glance() |>
    kableExtra::kable() |>
    kableExtra::kable_styling() |>
    kableExtra::scroll_box(width = '100%', height = '250px')
```

:::

::::


# Model in question

::::{.columns}

:::{.column}
```{r}
#| echo: true

 lm(mpg ~ horsepower, Auto) |>
    broom::augment() |> 
    summarise(mse = mean(.resid ^2))
```

:::

:::{.column}

```{r}
#| echo: true

lm(mpg ~ poly(horsepower,2), Auto) |>
    broom::augment() |> 
    summarise(mse = mean(.resid ^2))

```

:::

::::

# Model in question

[Selection: Would models with more flexibility prove better?]{.fragment fragment-index='1'}
<br><br>
[Performance: Does the second model have better MSE? Will this be true for any sample?]{.fragment fragment-index='2'}



# validation Set Approach 

**Split sample in training and Validation set**

```{r}
#| echo: true

rsample::initial_split(Auto,prop = .5) -> Auto_split 

Auto_split

Auto_train <- rsample::training(Auto_split)

Auto_validation_set <- rsample::testing(Auto_split)
```

# validation Set Approach

**Train model using training data**


```{r}
#| echo: true

lm(mpg ~  poly(horsepower,3), Auto_train) -> trained_model

head(predict(trained_model, Auto_validation_set))

tibble(
    y = Auto_validation_set$mpg,
    y_hat = predict(trained_model, Auto_validation_set),
    resid_sqr = (y - y_hat)^2
) |>
    summarise(mse = mean(resid_sqr, na.rm = T))

```

# Validation Set Approach

**Get MSE for all powers from 2 to 10**

```{r}
#| echo: true

# define a funciton

get_mse <- function(pow){

    # train the model - using trainging data
    lm(mpg ~ poly(horsepower,pow), Auto_train) -> trained_model

    # get mse
    tibble(
        y = Auto_validation_set$mpg,
        y_hat = predict(trained_model, Auto_validation_set),
        resid_sqr = (y - y_hat)^2
    ) |>
        summarise(mse = mean(resid_sqr, na.rm = T)) |>
        pull(mse) -> mse

    # Store appropriately

    tibble(
        pow_flexibility = pow,
        mse = mse
    )

}

```

# Validation set Approach

**Get MSE for all powers of 1 to 10**


```{r}
#| echo: true
#| output-location: slide
map(
    c(1:10),
    get_mse
) |>
    list_rbind() |>
    ggplot(aes(pow_flexibility,mse))+
    geom_point()+
    geom_line()+
    labs(
    x = "Flexibility",
    y = "MSE"
    )+
    theme_minimal()
```

# What happens if the sample changes

> For each power (level of flexibility) I run the model 10 times.

# Validation Set Approach

**adjust funciton to split every time when executed**

```{r}
#| echo: true

get_mse_spread <- function(pow){

    # repeats split for every iteration

    rsample::initial_split(Auto,prop = .5) -> Auto_split 

    Auto_train <- rsample::training(Auto_split)

    Auto_validation_set <- rsample::testing(Auto_split)

    # train the model - using trainging data
    lm(mpg ~ poly(horsepower,pow), Auto_train) -> trained_model

    # get mse
    tibble(
        y = Auto_validation_set$mpg,
        y_hat = predict(trained_model, Auto_validation_set),
        resid_sqr = (y - y_hat)^2
    ) |>
        summarise(mse = mean(resid_sqr, na.rm = T)) |>
        pull(mse) -> mse

    # Store appropriately

    tibble(
        pow_flexibility = pow,
        mse = mse
    )

    
}
```

# Validation Set Approach

**Execute 10 times for every power to get mse spread**


```{r}
#| echo: true
#| output-location: slide

map(
    rep(c(1:10),10) |> sort(),
    get_mse_spread
) |>
    list_rbind() |> 
    mutate(
        iteration = rep(letters[1:10],10)
    ) |>
    ggplot(aes(pow_flexibility,mse, colour = iteration))+
    geom_point()+
    geom_line(aes(group = iteration))+
    labs(
    x = "Flexibility",
    y = "MSE"
    )+
    theme_minimal() +
    theme(
        legend.position = "none"
    )


```

# Validation Set Approach

**Potential Problems**

[Validation set estimate of test MSE can be highly variable]{.fragment fragment-index='1'}
<br><br>
[Does not do well when number of observation are fewer. We end up not using all informaiton that we have to train the model. It might overestimate the test error rate.]{.fragment fragment-index='2'}

# Leave-one-out Cross-Validation

[Addresses the issue with Validation Set Approach, but is computationally costly.]{.fragment fragment-index='1'}
<br><br>
[For a data set of `n` observations, the model is fit `n` times using.]{.fragment fragment-index='2'}
<br><br>
[The model is fit using `n-1` observations  as training data in a manner where each observation is left out of the training data exactly once.]{.fragment fragment-index='3'}
<br><br>
[Test MSE is estimated using the error rates of all the left out observation predictions.]{.fragment fragment-index='4'}

# Leave-one-out Cross-Validation

**Begin by creating the splits**


```{r}
#| echo: true

rsample::loo_cv(Auto) -> Auto_loocv_split

Auto_loocv_split

```

# Leave-one-out Cross-Validation

**Function to Fit model on every training split and get error for each test observation**


```{r}
#| echo: true
get_error_obs <- function(split,pow){

    Auto_loocv_train <- rsample::training(Auto_loocv_split$splits[[split]])

    Auto_loocv_test <- rsample::testing(Auto_loocv_split$splits[[split]])

    mod <- lm(mpg ~ poly(horsepower,pow),data = Auto_loocv_train)

    broom::augment(mod, newdata = Auto_loocv_test) |>
        select(
            mpg, `.fitted`,`.resid`
        ) |>
            mutate(
                split = split,
                pow = pow
            )

}
```

# Leave-one-out Cross-Validation

**Execute Function to get errors for all test obs.**


```{r}
#| echo: true
#| cache: true
#| output-location: slide

pmap(
    list(
        split = rep(c(1:391),10),
        pow = rep(c(1:10),391) |> sort()
    ),
    get_error_obs
) |>
    list_rbind() -> error_obs_tab

error_obs_tab |>
    kableExtra::kable() |>
    kableExtra::kable_styling() |>
    kableExtra::scroll_box(width = '100%', height = '500px')


```

# Leave-one-out Cross-Validation

**Get MSE for all levels of flexibility (power)**


```{r}
#| echo: true
#| output-location: slide

error_obs_tab |>
    group_by(pow) |>
    summarise(
        mse = mean(`.resid`^2, na.rm = T)
    )|>
    ggplot(aes(pow,mse),colour = "blue")+
    geom_point()+
    geom_line()+
    labs(
    x = "Flexibility",
    y = "MSE"
    )+
    theme_minimal()

```

# Leave-one-out Cross-Validation

[LooCV is less biased than the Validation set approach as it uses almost all the data to train the model.]{.fragment fragment-index='1'}
<br><br>
[Test error rate estimates of LooCV are not as spread out as provided by validation set approach as it does not get affected by randomness of splits.]{.fragment fragment-index='2'}
<br><br>
[Though it is expensive to use computationally, especially for data that is large.]{.fragment fragment-index='3'}

# k-Fold Cross-Validation

[k-Fold CV addresses the computational issue with LooCV, LooCV is a soecial case of k-fold]{.fragment fragment-index='1'}
<br><br>
[The data is split in `k` parts, all parts should be nearly equal.]{.fragment fragment-index='2'}
<br><br>
[The first part is used as a Validation set, model is fit on the remaining `k-1` parts.]{.fragment fragment-index='3'}
<br><br>
[This is repeated till each of the `k` parts have been used as the validation set.]{.fragment fragment-index='4'}
<br><br>
[Test error rate is estimated as the average of all k validation set error rates.]{.fragment fragment-index='5'}

# k-Fold Cross-Validation

**Begin by creating the splits**

```{r}
#| echo: true

rsample::vfold_cv(Auto,v = 10) -> Auto_kfold_splits

Auto_kfold_splits
```

# k-Fold Cross-Validation

**Function to get $MSE_{k}$**

```{r}
#| echo: true

get_k_mse <- function(k,pow){

    Auto_ktrain <- rsample::training(Auto_kfold_splits$splits[[k]])

    Auto_ktest <- rsample::testing(Auto_kfold_splits$splits[[k]])

    mod<- lm(mpg ~ poly(horsepower,pow), Auto_ktrain)

    tibble(
        k = k,
        pow = pow,
        k_mse = broom::augment(
            mod,
            newdata = Auto_ktest
            ) |>
            summarise(
                mse = mean(`.resid`^2, na.rm=T)
            ) |>
                pull(mse)

    )

}
```

# k-Fold Cross-Validation

**Execute function to get $CV_k$ at different powers**


```{r}
#| echo: true
#| output-location: slide

pmap(
    list(
        k = rep(c(1:10),10),
        pow = rep(c(1:10),10) |> sort()
    ),

    get_k_mse
) |>
    list_rbind() |>
    group_by(pow) |>
    summarise(
        mse = mean(k_mse, na.rm = T)
    ) |>
    ggplot(aes(pow,mse),colour = "blue")+
    geom_point()+
    geom_line()+
    labs(
    x = "Flexibility",
    y = "MSE"
    )+
    theme_minimal()

```

# k-Fold Cross-Validation

**Create 10 reps of the k-fold split**

```{r}
#| echo: true

rsample::vfold_cv(Auto,v = 10, repeats = 100)-> Auto_kfold_splits_100reps

Auto_kfold_splits_100reps

```

# k-Fold Cross-Validation

**Function to Repeat the process for every power(1:10) 10 times**

```{r}
#| echo: true

get_k_repeats_mse <- function(itr, pow){
    
    Auto_ktrain <- rsample::training(Auto_kfold_splits_100reps$splits[[itr]])

    Auto_ktest <- rsample::testing(Auto_kfold_splits_100reps$splits[[itr]])

    mod <- lm(mpg ~ poly(horsepower,pow), Auto_ktrain)

    broom::augment(mod, newdata = Auto_ktest) |>
        select(`.resid`) |>
        mutate(
            pow = pow,
            rep = Auto_kfold_splits_100reps$id[itr],
            fold = Auto_kfold_splits_100reps$id2[itr]
        )  

}

```

# k-Fold Cross-Validation

```{r}
#| echo: true
#| output-location: slide

pmap(
    list(
        itr = c(1:1000),
        pow = rep(c(1:10),100) |> sort()
    ),
    get_k_repeats_mse
) |>
    list_rbind() |> 
    group_by(rep,fold,pow)|>
    summarise(
        mse = mean(`.resid`^2, na.rm = T)
    ) |> 
        ungroup()|>
        group_by(rep,pow)|>
        summarise(
        mse = mean(mse, na.rm = T)
        ) |> 
    ungroup()|> 
    ggplot(aes(pow,mse,colour = rep))+
    geom_point()+
    labs(
    x = "Flexibility",
    y = "MSE"
    )+
    theme_minimal() +
    theme(
        legend.position = "none"
    )

```

# k-Fold Cross-Validation

[k-Fold CV is the practical choice for most methods.]{.fragment fragment-index='1'}
<br><br>
[It balances the bias problem of validation set approach and the computational constraint of the LooCV]{.fragment fragment-index='2'}
<br><br>
[Due to the Bias-Variance trade-off it offers better estimation of test error rate compared to LooCV]{.fragment fragment-index='3'}

# Appling CV using {boot}


```{r}
#| echo: true

glm.fit <- glm(mpg ~ poly(horsepower,2), data = Auto)

boot::cv.glm(Auto, glm.fit, K = 10)$delta


```

# Exercise

> Get the k-fold MSE for the model you built for housing prices. Comapre it with the training MSE. 

# Exercise

Perform a complete analyses cycle on the `College` data from {ISLR2}.

carry out:

1. Study the data documentation
2. Exploratory and Descriptive Analyses
3. Develop a theory that you think dictates the response (number of applicaitons received) variable
4. build a model
5. perform model diagnostics
6. compare the training mse with the k-fold CV mse

# The Bootstrap - Motivation

**We revist one of the major questions of statistics**
<br><br>
> How to estimate a populaiton parameter using a sample statistic

<br><br>

Confidence Intervals are used to define the uncertainity around the estimate.

# The Bootstrap - Motivation

**Utopia**
<br><br>
 One way to do this is by taking many samples to generate the statistic of interest and measure the variability of the statistic. This can give a good sense of the variability of the original statistic. 

# The Bootstrap - Motivation

**Trouble in Paradise**
<br><br>

1. Sampling data is not cheap
2. neither is it possible to take repeated samples form a populaiton

# The Bootstrap

**Joy to the world**

> We sample from the sample, repeatedly with replacement, instead of sampling from the population.This is bootstraping.

# The Bootstrap

Used in scenarios where goal is to estimate the unknown value of a population parameter and the data is generated from random sampling from a population.
<br><br>
Especially useful when there is no simple theory on how a statistic changes from sample to sample. Bootstrapping provides a computational approach instead of a mathematical theory route.

# The Bootstrap - Intuition and Practice


![From IMS2e](https://openintro-ims.netlify.app/images/boot1propboth.png)

# The Bootstrap - Medical Consultant

**Context**
<br><br>

> A consultant tried to attract clients by mentioning that average complicaiton rate for liver donor surgeries in the US is 10%. However, only 3 of her 62 clients have had complications. 
<br><br>

**should she be hired?**

# The Bootstrap - Medical Consultant

Let us denote her true populaiton complication rate as $p$
<br><br>
Let $\hat{p}$ be the estimate of $p$. From the observed sample $\hat{p} = 3/62 = 0.048$

# The Bootstrap - Medical Consultant

**Caution: this is not an assessment of a causal claim**

We cant prove/assess from the given data that the consultant's involvement reduces the complicaiton rates.
<br><br>
We can only estimate the population complication parameter for her work.

# The Bootstrap - Medical Consultant

```{r}
#| echo: true

observed_sample <- c(rep(1,3), rep(0,59))      #<1>

sample(
    x = observed_sample,
    size = length(observed_sample),
    replace = T
    )                                          #<2>
```

1. Create the observed smaple with code. 3 complications represented as 1 and no complications represented as 0.

2. Draw a bootstrap resample with replacement of the same size

# The Bootstrap - Medical Consultant


```{r}
#| echo: true

map_vec(                                 # <1>
    c(1:10000),                          # <2>
    ~ sample(                            # <3>
        observed_sample,
        length(observed_sample),
        replace = T
    ) |>
        mean()                           # <4>
)  -> bootstrap_resample_complication_rates

bootstrap_resample_complication_rates |> head()
```

1. `map` funciton allows to repeat a set of code
2. Number of times I want to run the code in step 3 
3. Code to create a bootstrap resample
4. Take mean to get complication rate for each bootstrap resample

# The Bootstrap - Medical Consultant

```{r}
#| echo: true
#| output-location: slide

tibble(
    com_est = bootstrap_resample_complication_rates
    ) |>
        ggplot(aes(com_est)) + 
        geom_histogram(aes(fill = 
        ifelse(
            com_est > quantile(bootstrap_resample_complication_rates, 
                    0.025
                    ) &
                    com_est < quantile(bootstrap_resample_complication_rates, 
                    0.975
                    ),
            "lightblue",
            "steelblue"
        ))) +
        scale_fill_identity()+
        geom_vline(
            aes(
                xintercept = 
                    quantile(bootstrap_resample_complication_rates, 
                    0.025
                    )
                )
            )+
        geom_vline(
            aes(
                xintercept = 
                    quantile(bootstrap_resample_complication_rates, 
                    0.975
                    )
                )
            )+
        labs(
        x = "Bootstrap sample estimates of compication rates",
        y = "Count",
        title = "10,000 Bootstrapped Proportoins"
        ) +
        theme_minimal() +
        theme(
            legend.position = "none",
            plot.title.position = "plot"
        ) 
```

## Side note on getting quantile values

```{r}
#| echo: true

quantile(bootstrap_resample_complication_rates, 0.10)

sort(bootstrap_resample_complication_rates)[round(length(bootstrap_resample_complication_rates) *0.10)]


```

# Exercise

> You wish to estimate the proportion of videos on youtube that are shot outdoors. (Any video, in full or in part that is shot outdoors)

<br><br>

You take a random sample of 128 videos and find that 47 of these are shout outdoors.

Bootstrap the smaple to and calcualte the statistic for interest for each sample. The create a 90% confidence interval. What should be the point estimate?

# Bootstrap - paried mean diff

**Is the difference in prices real ?**

```{r}
#| echo: false
#| 
ucla_textbooks_f18 |> 
    select(amazon_new,bookstore_new) |>
    filter(!is.na(amazon_new) & !is.na(bookstore_new)) |>
    kableExtra::kable() |>
    kableExtra::kable_styling() |>
    kableExtra::scroll_box(width = '100%', height = '500px')

ucla_textbooks_f18 |> 
    select(amazon_new,bookstore_new) |>
    filter(!is.na(amazon_new) & !is.na(bookstore_new)) -> book_prices

```

# Bootstrap - paired mean diff

```{r}
#| echo: true
#| output-location: slide
    
book_prices|>
    mutate(
    diff = bookstore_new - amazon_new
    ) |>
    pull(diff) -> diff


map_vec(
    c(1:1000),
    ~sample(
        diff,
        length(diff),
        T
    )|>
        mean()
) -> mean_diffs


quantile(mean_diffs, 0.005) -> l_ci_p
quantile(mean_diffs, 0.995) -> u_ci_p

mean(mean_diffs) - 2.58*sd(mean_diffs) -> l_ci_se
mean(mean_diffs) + 2.58*sd(mean_diffs) -> u_ci_se

tibble(
    x = mean_diffs
) |>
    ggplot(aes(x)) +
    geom_histogram(fill = "steelblue", colour = "white") +
    geom_vline(aes(xintercept = l_ci_p),
    linetype = 2, colour = "lightblue")+
    geom_vline(aes(xintercept = u_ci_p),
    linetype = 2, colour = "lightblue")+
    geom_vline(aes(xintercept = l_ci_se),
    linetype = 3, colour = "red")+
    geom_vline(aes(xintercept = u_ci_se),
    linetype = 3, colour = "red")+
    labs(
        x = "Bootstarp means of difference in prices",
        y = "Count",
        title = "1000 Bootstrap Means Distribution",
        subtitle = "red lines are SE CI and blue lines are percentile CI"
    ) +
    theme_minimal() +
    theme(
            plot.title.position = "plot"
        ) 

```

# Readings

ISLR CH5: 5.1, 5.3.1 - 5.3.3<br><br>
IMS: CH12, CH21.2 and realted exercise